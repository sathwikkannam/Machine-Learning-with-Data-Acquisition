{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "acc_names = ['ax', 'ay', 'az']\n",
    "rate_gyro_names = ['gx', 'gy', 'gz']\n",
    "lab_1_positions = [\"Laying_down\", \"Standing_up\", \"Walking\"]\n",
    "sensors = [\"Accelerometer\", \"Gyroscope\"]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "51826f4cae1bec0a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Helper functions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "12a81bf78b7b6cf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_paths_based_on(positions: list[str], set_name: str) -> list[list[str]]:\n",
    "    return [\n",
    "        [f\"../Binaries/{set_name}/{pos}-1.pkl\", f\"../Binaries/{set_name}/{pos}-2.pkl\"]\n",
    "        for pos in positions\n",
    "    ]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "92485dbc2fb0e556"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data analysis"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "72a16f9192500118"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def read_csv(filename: str, names: list[str]) -> pd.DataFrame:\n",
    "    return pd.read_csv(filename, usecols=[1, 2, 3], names=names, skiprows=[0])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "40af569b91ed3456"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def read_recordings(positions: list[str] = lab_1_positions) -> dict[str:pd.DataFrame]:\n",
    "    recordings = {}\n",
    "\n",
    "    for position in positions:\n",
    "        for i in range(1, 4):\n",
    "            for sensor in sensors:\n",
    "                dataframe = (\n",
    "                    read_csv(f\"../Data/ML_Lab_1_{position}_{i}/{sensor}.csv\", names=acc_names\n",
    "                    if sensor == \"Accelerometer\"\n",
    "                    else rate_gyro_names)\n",
    "                )\n",
    "                recordings[f\"{position} {sensor} {i}\"] = dataframe\n",
    "\n",
    "    return recordings\n",
    "        "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4df64da17db8de69"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Plot the accelerometer values using the plot functions accessible for panda dataframes. Plot all accelerometer values, i.e. all samples for all components of the accelerometer vector."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3d202767d9214e79"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "raw_dfs = read_recordings()\n",
    "\n",
    "for key in raw_dfs:\n",
    "    raw_dfs[key].plot(title=key)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "15ee80900b6f6d3a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### What are we measuring with the accelerometer and rate_gyro?\n",
    "The Accelerometer measures the rotation of the device. Hence, we can determine the orientation of the device.\n",
    "In Laying down position, the z-axis reports -9.8m/s^2, hence the screen-side of the phone is pointing down. The z-axis pointing out of the screen is negative. \n",
    "\n",
    "Note: Walking includes turning.\n",
    "\n",
    "Gyroscope measures the angular acceleration in each axis."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7240f826d8e4c3ef"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocessing the data\n",
    "#### Once again plot the data for each recording. You should see some irregular data in the beginning of the recording and in the end of the recording."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ab67163a1913baed"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Why do you have these irregularities in your recordings? Or maybe you do not, how come?\n",
    "Collected the data with the 7 seconds delay in the beginning to get in position."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3f846c9566152260"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Create a python function that can read one accelerometer file and one rategyro file, remove a specific number of samples in the beginning and in the end and output a dataframe with six columns, that is all the accelerometer and rateygyro attributes. What do you need as input to the function?"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4660a4b0b3030b9e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def pre_process_file(acc_file: str, rate_gyro_file: str, n: int) -> pd.DataFrame:\n",
    "    acc_frame = read_csv(acc_file, acc_names)\n",
    "    rate_gyro_frame = read_csv(rate_gyro_file, rate_gyro_names)\n",
    "\n",
    "    acc_frame.drop(acc_frame.head(n).add(acc_frame.tail(n)).index, inplace=True)\n",
    "    rate_gyro_frame.drop(rate_gyro_frame.head(n).add(rate_gyro_frame.tail(n)).index, inplace=True)\n",
    "\n",
    "    return (pd\n",
    "            .concat([acc_frame, rate_gyro_frame], axis='columns', ignore_index=True)\n",
    "            .rename({index: label for index, label in enumerate(acc_names + rate_gyro_names)}, axis='columns')\n",
    "            .dropna(how='any'))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4e063e0853b398cd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Calls pre_process_file() for all accelerometer and rate_gyro csv's for each class/position"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a0de818de1feb70e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def merger(remove_n: int, positions: list[str] = lab_1_positions) -> dict[str:pd.DataFrame]:\n",
    "    dfs = {}\n",
    "\n",
    "    for pos in positions:\n",
    "        for x in range(1, 4):\n",
    "            processed_dataframe = pre_process_file(acc_file=f\"../Data/ML_Lab_1_{pos}_{x}/Accelerometer.csv\",\n",
    "                                                   rate_gyro_file=f\"../Data/ML_Lab_1_{pos}_{x}/Gyroscope.csv\",\n",
    "                                                   n=remove_n)\n",
    "            dfs[f\"{pos}-{x}\"] = processed_dataframe\n",
    "\n",
    "    return dfs"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "60380a64e7d87577"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pre_processed_dataframes = merger(remove_n=3)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9bf173698be80b85"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Processed dataframes"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d25df57caf55ddf8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in pre_processed_dataframes:\n",
    "    print(f\"{i}\\n{pre_processed_dataframes[i]}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f933af8137b3ac9e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Python\n",
    "#### Store each dataframe, one for each recording, in a binary file using the to_pickle function, and divide the data into two sets, training set and test set. Store 2 of 3 files in the training folder and 1 of 3 files in the test folder. Note: it is the binary pickle files we talk about"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5aac8aa622a8955b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def split_train_test_sets(processed_dataframes: dict[str:pd.DataFrame]):\n",
    "    for i in processed_dataframes:\n",
    "        if i.__contains__(\"-1\") or i.__contains__(\"-2\"):\n",
    "            processed_dataframes[i].to_pickle(f\"../Binaries/Training/{i}.pkl\")\n",
    "\n",
    "        else:\n",
    "            processed_dataframes[i].to_pickle(f\"../Binaries/Test/{i}.pkl\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2033106acb357c25"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "split_train_test_sets(pre_processed_dataframes)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1b287cfcd1c78105"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Create a python function that can read all binary-files from one class. The function should return a dataframe x with all the data and also a column with information of which class the data belongs to. The dataframe has now 7 columns.\n",
    "\n",
    "##### Note: Only applied to the training set"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "67c3dc89bd3b313f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def merge_measurements_by_class(\n",
    "        recordings: list[str],\n",
    "        class_name: str,\n",
    "        store_as_pickle: bool = False,\n",
    "        directory: str = \"../Binaries/Class dataframes/\"\n",
    ") -> pd.DataFrame:\n",
    "    \n",
    "    df = pd.concat(list(map(lambda i: pd.read_pickle(i), recordings)), axis='rows', ignore_index=True)\n",
    "    df['class'] = class_name\n",
    "\n",
    "    if store_as_pickle:\n",
    "        df.to_pickle(directory + df['class'][0] + \".pkl\")\n",
    "\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c2a2cf22541883f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Merge the training set into three dataframes (one for each class) and store it as a pickle file"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3cc672eab19a0b7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def merge_recordings_by_rows(classes : list[str], set_name: str = 'Training') -> list[pd.DataFrame]:\n",
    "    paths = get_paths_based_on(positions=classes, set_name=set_name)\n",
    "    return [\n",
    "        merge_measurements_by_class(\n",
    "            recordings=_class,\n",
    "            class_name=_class[0].replace(f\"../Binaries/{set_name}/\", \"\").replace(\"-1.pkl\", \"\").replace(\"-2.pkl\", \"\"),\n",
    "            store_as_pickle=True)\n",
    "\n",
    "        for _class in paths\n",
    "    ]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6ef5b53ffabad4e2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class_dfs = merge_recordings_by_rows(lab_1_positions)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "da609d1d9c638b6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Display the three classes"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "faeb93520de5b6b9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(*class_dfs, sep='\\n')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ec7cf8b4efc96c4b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
